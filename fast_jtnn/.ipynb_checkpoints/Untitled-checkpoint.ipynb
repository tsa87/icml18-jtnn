{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nnutils import create_var, create_onehot, log_standard_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, y_size):\n",
    "        self.fc1 = nn.Linear(input_size, latent_size)\n",
    "        self.fc2 = nn.Linear(latent_size, y_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.LeakyReLU(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNVAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, y_size, alpha):\n",
    "        self.y_size = y_size\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, y_size),\n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.z_mean = nn.Linear(hidden_size, latent_size)\n",
    "        self.z_var = nn.Linear(hidden_size, latent_size)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size+y_size, hidden_size),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size, input_size),\n",
    "        )\n",
    "        \n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def rsample(self, h):\n",
    "        batch_size = h.size(0)\n",
    "        z_mean = self.z_mean(h)\n",
    "        z_log_var = -torch.abs(self.z_var(h))\n",
    "        kl_loss = -0.5 * torch.sum(1.0 + z_log_var - z_mean * z_mean - torch.exp(z_log_var)) / batch_size\n",
    "        epsilon = create_var(torch.randn_like(z_mean))\n",
    "        z_vecs = z_mean + torch.exp(z_log_var / 2) * epsilon\n",
    "        return z_vecs, kl_loss \n",
    "        \n",
    "    \n",
    "    def decode(self, z, y):\n",
    "        latent = torch.cat((z, y), 1)\n",
    "        x_hat = self.decoder(latent)\n",
    "        return x_hat\n",
    "    \n",
    "    \n",
    "    def compute_reconstruction_loss(x, z, y):\n",
    "        x_hat = decode(z, y)\n",
    "        return self.cross_entropy_loss(x_hat, x)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        is_labeled = False if y is None else True\n",
    "        loss, pred_loss, pred_acc = 0, 0, 0\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        y_hat = self.classifier(x)\n",
    "        z, kl_div = self.rsample(h)\n",
    "        \n",
    "        logy = torch.mean(log_standard_categorical(y_hat))\n",
    "        loss = logy + kl_div\n",
    "        \n",
    "        if is_labeled:\n",
    "            y = create_var(y)\n",
    "            pred_loss = self.cross_entropy_loss(y_hat, y) * self.alpha\n",
    "            pred_acc = float((y_hat == y).sum().item()) / y.size(0)\n",
    "            recon_loss = self.compute_reconstruction_loss(x, z, y)\n",
    "            loss += pred_loss + recon_loss\n",
    "        else:\n",
    "            for i in range(self.y_size):\n",
    "                y = create_onehot(len(x_batch), self.y_size, i)\n",
    "                recon_loss = self.compute_reconstruction_loss(x, z, y) \n",
    "                loss += recon_loss * torch.mean(y_hat[:, i])     \n",
    "            \n",
    "            y_hat_entropy = torch.sum(y_hat * torch.log(y_hat + 1e-8))\n",
    "            loss += y_hat_entropy\n",
    "            \n",
    "        return loss, pred_loss, pred_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
