{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from utils import time_since\n",
    "import traceback\n",
    "\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import math, random\n",
    "import argparse\n",
    "from collections import deque\n",
    "import cPickle as pickle\n",
    "\n",
    "from fast_jtnn import *\n",
    "import rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = 10 + 3 \n",
    "target_unlabeled_percentage = 0.75\n",
    "early_stop_thresh = 2\n",
    "\n",
    "load_epoch = 0\n",
    "alpha = 100 #0.1 * len_unlabelled / len_labelled\n",
    "\n",
    "hidden_size=56 #450\n",
    "batch_size=2\n",
    "latent_size=28\n",
    "depthT=20\n",
    "depthG=3\n",
    "y_size=1\n",
    "\n",
    "lr=1e-3\n",
    "clip_norm=50.0\n",
    "beta=0.0\n",
    "step_beta=0.002\n",
    "max_beta=1.0\n",
    "warmup=40 #40000\n",
    "\n",
    "total_epoch=5\n",
    "test_epoch=1\n",
    "anneal_rate=0.9\n",
    "anneal_iter=40 #40000\n",
    "kl_anneal_iter=20 #2000\n",
    "\n",
    "save_iter=50\n",
    "print_iter=5\n",
    "\n",
    "num_workers = 4\n",
    "has_cuda = torch.cuda.is_available()\n",
    "\n",
    "save_dir = 'data/qm9/model'\n",
    "train_folder = 'fast_molvae/qm9_processed/train'\n",
    "test_folder = 'fast_molvae/qm9_processed/test'\n",
    "vocab_file = 'data/qm9/vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [x.strip(\"\\r\\n \") for x in open(vocab_file)]\n",
    "vocab = Vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemiJTNNVAERegressor(\n",
      "  (jtnn): JTNNEncoder(\n",
      "    (embedding): Embedding(1786, 56)\n",
      "    (outputNN): Sequential(\n",
      "      (0): Linear(in_features=112, out_features=56, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (GRU): GraphGRU(\n",
      "      (W_z): Linear(in_features=112, out_features=56, bias=True)\n",
      "      (W_r): Linear(in_features=56, out_features=56, bias=False)\n",
      "      (U_r): Linear(in_features=56, out_features=56, bias=True)\n",
      "      (W_h): Linear(in_features=112, out_features=56, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): JTNNDecoder(\n",
      "    (embedding): Embedding(1786, 56)\n",
      "    (W_z): Linear(in_features=112, out_features=56, bias=True)\n",
      "    (U_r): Linear(in_features=56, out_features=56, bias=False)\n",
      "    (W_r): Linear(in_features=56, out_features=56, bias=True)\n",
      "    (W_h): Linear(in_features=112, out_features=56, bias=True)\n",
      "    (W): Linear(in_features=70, out_features=56, bias=True)\n",
      "    (U): Linear(in_features=70, out_features=56, bias=True)\n",
      "    (U_i): Linear(in_features=112, out_features=56, bias=True)\n",
      "    (W_o): Linear(in_features=56, out_features=1786, bias=True)\n",
      "    (U_o): Linear(in_features=56, out_features=1, bias=True)\n",
      "    (pred_loss): CrossEntropyLoss()\n",
      "    (stop_loss): BCEWithLogitsLoss()\n",
      "  )\n",
      "  (jtmpn): JTMPN(\n",
      "    (W_i): Linear(in_features=40, out_features=56, bias=False)\n",
      "    (W_h): Linear(in_features=56, out_features=56, bias=False)\n",
      "    (W_o): Linear(in_features=91, out_features=56, bias=True)\n",
      "  )\n",
      "  (mpn): MPN(\n",
      "    (W_i): Linear(in_features=50, out_features=56, bias=False)\n",
      "    (W_h): Linear(in_features=56, out_features=56, bias=False)\n",
      "    (W_o): Linear(in_features=95, out_features=56, bias=True)\n",
      "  )\n",
      "  (A_assm): Linear(in_features=14, out_features=56, bias=False)\n",
      "  (assm_loss): CrossEntropyLoss()\n",
      "  (T_mean): Linear(in_features=57, out_features=14, bias=True)\n",
      "  (T_var): Linear(in_features=57, out_features=14, bias=True)\n",
      "  (G_mean): Linear(in_features=57, out_features=14, bias=True)\n",
      "  (G_var): Linear(in_features=57, out_features=14, bias=True)\n",
      "  (predictor): Sequential(\n",
      "    (0): Linear(in_features=112, out_features=56, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=56, out_features=2, bias=True)\n",
      "  )\n",
      "  (pred_loss): MSELoss()\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsa87/miniconda3/envs/python2/lib/python2.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "model = SemiJTNNVAERegressor(vocab, hidden_size, latent_size, y_size, depthT, depthG, alpha)\n",
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = NNVAE(1024, hidden_size, latent_size, y_size, alpha)\n",
    "# print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if has_cuda: model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    if param.dim() == 1:\n",
    "        nn.init.constant_(param, 0)\n",
    "    else:\n",
    "        nn.init.xavier_normal_(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #Params: 392K\n"
     ]
    }
   ],
   "source": [
    "if load_epoch > 0:\n",
    "    model.load_state_dict(torch.load(save_dir + \"/model.iter-\" + str(load_epoch)))\n",
    "    \n",
    "print \"Model #Params: %dK\" % (sum([x.nelement() for x in model.parameters()]) / 1000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, anneal_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_norm = lambda m: math.sqrt(sum([p.norm().item() ** 2 for p in m.parameters()]))\n",
    "grad_norm = lambda m: math.sqrt(sum([p.grad.norm().item() ** 2 for p in m.parameters() if p.grad is not None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing this because 20% of labelled data got lost in test\n",
    "tracker = IndexTracker(train_folder, label_idx=label_col, label_pct=(1-target_unlabeled_percentage)/0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, scheduler, use_moltree=True, patience=3):\n",
    "    best_loss = np.inf\n",
    "    no_improvement = 0\n",
    "    \n",
    "    beta = 0\n",
    "    total_step = load_epoch\n",
    "    \n",
    "    start = time.time()\n",
    "    for epoch in xrange(total_epoch):\n",
    "        \n",
    "        preds = np.array([])\n",
    "        targets = np.array([])\n",
    "\n",
    "        # Evaluation loop\n",
    "        if epoch % test_epoch == 0:\n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "\n",
    "                if use_moltree:\n",
    "                    test_loader = MolTreeFolder(test_folder, vocab, continous=True, batch_size=batch_size, feature_idx=1, label_idx=label_col, num_workers=num_workers, test=True)\n",
    "                else:\n",
    "                    test_loader = BaseFolder(test_folder, continous=True, batch_size=batch_size, feature_idx=2, label_idx=label_col, num_workers=num_workers, test=True)\n",
    "                \n",
    "                cum_loss = 0\n",
    "                for (supervised_batch, _) in test_loader:  \n",
    "                    try:           \n",
    "                        if len(supervised_batch['labels']) == batch_size:\n",
    "                            supervised_input = supervised_batch['data']\n",
    "                            labels = supervised_batch['labels'].cuda() if torch.cuda.is_available() else supervised_batch['labels']\n",
    "                                \n",
    "                            loss, clsf_loss, clsf_acc, (pred, target) = model(supervised_input, labels, beta)\n",
    "\n",
    "                            preds = np.append(preds, pred.cpu().detach().numpy())\n",
    "                            targets = np.append(targets, target.cpu().detach().numpy())\n",
    "                                            \n",
    "                    except Exception as e:\n",
    "                        traceback.print_exc()\n",
    "                        continue\n",
    "                \n",
    "                print (targets, preds)\n",
    "                print 'time: %s' % time_since(start)\n",
    "                print \"[Test] Loss: %.3f, Clsf_loss: %.2f\" % (loss, clsf_loss)\n",
    "                \n",
    "                if cum_loss < best_loss:\n",
    "                    best_loss = cum_loss\n",
    "                    no_improvement = 0\n",
    "                else:\n",
    "                    no_improvement += 1\n",
    "                    if no_improvement > patience:\n",
    "                        print \"Ran out of patience, stop\"\n",
    "                        return \n",
    "                \n",
    "                \n",
    "        if use_moltree:\n",
    "            train_loader = MolTreeFolder(train_folder, vocab, continous=True, batch_size=batch_size, feature_idx=1, label_idx=label_col, num_workers=num_workers, index_tracker=tracker)\n",
    "        else:\n",
    "            train_loader = BaseFolder(train_folder, continous=True, batch_size=batch_size, feature_idx=2, label_idx=label_col, num_workers=num_workers, index_tracker=tracker)\n",
    "        \n",
    "        cache = np.zeros(3)\n",
    "        model.train()\n",
    "\n",
    "        for (supervised_batch, unsupervised_batch) in train_loader: \n",
    "            try:\n",
    "                if len(supervised_batch['labels']) == batch_size and len(unsupervised_batch['labels']) == batch_size:\n",
    "                    model.zero_grad()\n",
    "\n",
    "                    total_step += 1\n",
    "                    labels = supervised_batch['labels'].cuda() if torch.cuda.is_available() else supervised_batch['labels']\n",
    "                    \n",
    "                    unsupervised_loss, _, _, _ = model(unsupervised_batch['data'], None, beta)\n",
    "                    supervised_loss, clsf_loss, clsf_acc, (pred, target) = model(supervised_batch['data'], labels, beta)\n",
    "            \n",
    "                    loss = unsupervised_loss + supervised_loss\n",
    "                    \n",
    "                    cache += np.array([loss, clsf_loss, clsf_acc], dtype=np.float)\n",
    "                    \n",
    "                    loss.backward()\n",
    "                    nn.utils.clip_grad_norm_(model.parameters(), clip_norm)\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    if total_step % save_iter == 0:\n",
    "                        print \"Saving model to \" + save_dir + \"/model.iter-\" + \"at step: \" + str(total_step)\n",
    "                        torch.save(model.state_dict(), save_dir + \"/model.iter-\" + str(total_step))\n",
    "\n",
    "                    if total_step % anneal_iter == 0:\n",
    "                        scheduler.step()\n",
    "                        print \"learning rate: %.6f\" % scheduler.get_lr()[0]\n",
    "\n",
    "                    if total_step % kl_anneal_iter == 0 and total_step >= warmup:\n",
    "                        beta = min(max_beta, beta + step_beta)\n",
    "\n",
    "                    if total_step % print_iter == 0:\n",
    "                        cache /= print_iter\n",
    "                        print \"Epoch: %d | Iter: %d\" % (epoch, total_step)\n",
    "                        print \"[Test] Loss: %.3f, Clsf_loss: %.2f, Clsf_acc: %.2f\" % (cache[0], cache[1], cache[2])\n",
    "                        sys.stdout.flush()\n",
    "                        cache *= 0\n",
    "\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast_molvae/qm9_processed/test/tensors-9.pkl opened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "Traceback (most recent call last):\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "Traceback (most recent call last):\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "Traceback (most recent call last):\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "Traceback (most recent call last):\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    jtmpn_holder = JTMPN.tensorize(cands, mess_dict)\n",
      "    'data': tensorize(self.data[idx], self.vocab, assm=self.assm),\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "    batch_idx.extend([i] * len(node.cands))\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "  File \"fast_jtnn/datautils.py\", line 286, in __getitem__\n",
      "    print self.data[idx]\n",
      "    print self.data[idx]\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "  File \"fast_jtnn/datautils.py\", line 339, in tensorize\n",
      "    batch_idx.extend([i] * len(node.cands))\n",
      "    batch_idx.extend([i] * len(node.cands))\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "  File \"fast_jtnn/jtmpn.py\", line 122, in tensorize\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "    fatoms = torch.stack(fatoms, 0)\n",
      "RuntimeError: stack expects a non-empty TensorList\n",
      "RuntimeError: stack expects a non-empty TensorList\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
